---
apiVersion: v1
kind: Service
metadata:
  name: kimi-k2-vllm
  namespace: llm-models
  labels:
    app: kimi-k2
    component: inference-server
  annotations:
    description: "Service for Kimi K2 vLLM inference API"
spec:
  type: ClusterIP
  selector:
    app: kimi-k2
    component: inference-server
  ports:
    - name: http
      port: 8000
      targetPort: 8000
      protocol: TCP
  sessionAffinity: ClientIP
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 10800  # 3 hours for long-running requests
